{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3DsXqQ05FNj",
        "outputId": "1c4f0c42-e2fb-44da-bc14-eba5c939227f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.13.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.6)\n",
            "Downloading pymongo-4.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, dnspython, pymongo, bs4\n",
            "Successfully installed bs4-0.0.2 dnspython-2.7.0 pymongo-4.11.3 python-dotenv-1.0.1\n",
            "Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.11/dist-packages (4.11.3)\n",
            "\u001b[33mWARNING: pymongo 4.11.3 does not provide the extra 'srv'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo[srv]) (2.7.0)\n",
            "Mounted at /content/drive\n",
            "GPU Available: True\n",
            "GPU Device Name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Colab-specific installations\n",
        "!pip install transformers sentencepiece pymongo bs4 requests python-dotenv\n",
        "!pip install \"pymongo[srv]\"\n",
        "\n",
        "import datetime\n",
        "import requests\n",
        "import os\n",
        "import torch\n",
        "from bs4 import BeautifulSoup\n",
        "from pymongo.mongo_client import MongoClient\n",
        "from pymongo.server_api import ServerApi\n",
        "from dotenv import load_dotenv\n",
        "from datetime import datetime, timedelta\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to access or save files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Hugging Face transformers\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Check GPU availability\n",
        "print(\"GPU Available:\", torch.cuda.is_available())\n",
        "print(\"GPU Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "\n",
        "# Load environment variables (you may need to create this file in your Google Drive)\n",
        "load_dotenv('/content/drive/MyDrive/cred.env')\n",
        "\n",
        "mongo_username = 'hidden",
        "mongo_password = 'hidden"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MongoDB setup\n",
        "uri = 'mongodb+srv://hidden.km1fx.mongodb.net/?retryWrites=true&w=majority&appName=buildathon'\n",
        "\n",
        "client = MongoClient(uri, server_api=ServerApi('1'))\n",
        "\n",
        "# Send a ping to confirm a successful connection\n",
        "try:\n",
        "    client.admin.command('ping')\n",
        "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "db = client['news_scraper']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "-HMY5RSxYRhP",
        "outputId": "50f9e0b7-bde7-4d23-c605-15d6089d25bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConfigurationError",
          "evalue": "The DNS query name does not exist: _mongodb._tcp.buildathon.km1fx.mongodb.net.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConfigurationError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-824654d368ea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0muri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mongodb+srv://hidden@buildathon.km1fx.mongodb.net/?retryWrites=true&w=majority&appName=buildathon'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMongoClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mServerApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Send a ping to confirm a successful connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/synchronous/mongo_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, host, port, document_class, tz_aware, connect, type_registry, **kwargs)\u001b[0m\n\u001b[1;32m    782\u001b[0m                         \u001b[0mkeyword_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcased_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"connecttimeoutms\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m                     )\n\u001b[0;32m--> 784\u001b[0;31m                 res = uri_parser.parse_uri(\n\u001b[0m\u001b[1;32m    785\u001b[0m                     \u001b[0mentity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                     \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/uri_parser.py\u001b[0m in \u001b[0;36mparse_uri\u001b[0;34m(uri, default_port, validate, warn, normalize, connect_timeout, srv_service_name, srv_max_hosts)\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mconnect_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnect_timeout\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"connectTimeoutMS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0mdns_resolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SrvResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfqdn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnect_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrv_service_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrv_max_hosts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m         \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdns_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hosts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m         \u001b[0mdns_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdns_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdns_options\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/srv_resolver.py\u001b[0m in \u001b[0;36mget_hosts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_hosts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_srv_response_and_hosts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/srv_resolver.py\u001b[0m in \u001b[0;36m_get_srv_response_and_hosts\u001b[0;34m(self, encapsulate_errors)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencapsulate_errors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     ) -> tuple[resolver.Answer, list[tuple[str, Any]]]:\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencapsulate_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# Construct address tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymongo/srv_resolver.py\u001b[0m in \u001b[0;36m_resolve_uri\u001b[0;34m(self, encapsulate_errors)\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;31m# Else, raise all errors as ConfigurationError.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConfigurationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConfigurationError\u001b[0m: The DNS query name does not exist: _mongodb._tcp.buildathon.km1fx.mongodb.net."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Use an open-source model for summarization, optimized for T4 GPU\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to('cuda')\n",
        "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer, device=0)  # Use GPU\n",
        "\n",
        "# Define the custom prompt template\n",
        "prompt_template = '''Summarize the following news article in a concise paragraph, focusing on the main highlights.\n",
        "Remove any text not directly related to the article content. Ensure the summary includes the publishing date if available.\n",
        "Article text: {article}'''\n",
        "\n",
        "# Instantiate the sentiment analysis pipeline\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\", device=0)  # Use GPU\n"
      ],
      "metadata": {
        "id": "LlSDIOT5YS3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to get text from URL using BeautifulSoup\n",
        "def get_text_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        html = response.text\n",
        "        soup = BeautifulSoup(html, 'html.parser')\n",
        "        text = soup.get_text()\n",
        "        return text.strip()\n",
        "    else:\n",
        "        print(f\"Failed to fetch data from URL: {url}, status code: {response.status_code}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "hHmFWMucYU-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define liquidity-related keywords\n",
        "liquidity_keywords = [\n",
        "    \"liquidity\", \"cash flow\", \"debt\", \"financing\", \"credit\",\n",
        "    \"solvency\", \"funding\", \"capital\"\n",
        "]\n",
        "\n",
        "# Define critical event keywords\n",
        "critical_event_keywords = [\n",
        "    \"bankruptcy\", \"lawsuit\", \"regulatory action\", \"recall\", \"data breach\",\n",
        "    \"fraud\", \"scandal\", \"accident\", \"disaster\", \"layoffs\"\n",
        "]\n",
        "\n",
        "# Initialize aggregation variables\n",
        "all_sentiments = []\n",
        "all_liquidity_impacts = []\n",
        "all_critical_events = []\n",
        "all_decisions = []\n",
        "total_articles_analyzed = 0\n",
        "\n",
        "def clean_text(primary_text):\n",
        "    try:\n",
        "        # Format the custom prompt with the article's primary text\n",
        "        formatted_prompt = prompt_template.format(article=primary_text)\n",
        "\n",
        "        input_length = len(formatted_prompt.split())\n",
        "        calculated_max_length = int(input_length * 0.5)\n",
        "        max_length = max(50, min(150, calculated_max_length))\n",
        "\n",
        "        # Dynamically set min_length as 30% of max_length, ensuring it's reasonable\n",
        "        min_length = max(30, int(max_length * 0.3))\n",
        "\n",
        "        # Use the summarization pipeline\n",
        "        summary = summarizer(\n",
        "            formatted_prompt,\n",
        "            max_length=24,\n",
        "            min_length=1,\n",
        "            do_sample=False\n",
        "        )[0]['summary_text']\n",
        "\n",
        "        # Perform sentiment analysis on the summary\n",
        "        sentiment = sentiment_analyzer(primary_text)[0]\n",
        "\n",
        "        return summary, sentiment\n",
        "    except Exception as e:\n",
        "        print(f\"Error cleaning text: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Function to forecast liquidity impact\n",
        "def forecast_liquidity(summary, sentiment):\n",
        "    summary_lower = summary.lower()\n",
        "    liquidity_impact = \"Neutral\"\n",
        "\n",
        "    if any(keyword in summary_lower for keyword in liquidity_keywords):\n",
        "        if sentiment['label'] == 'NEGATIVE':\n",
        "            liquidity_impact = \"Negative Impact on Liquidity\"\n",
        "        elif sentiment['label'] == 'POSITIVE':\n",
        "            liquidity_impact = \"Positive Impact on Liquidity\"\n",
        "    return liquidity_impact\n",
        "\n",
        "# Function to check for critical events\n",
        "def check_critical_events(summary):\n",
        "    summary_lower = summary.lower()\n",
        "    critical_events = []\n",
        "\n",
        "    for keyword in critical_event_keywords:\n",
        "        if keyword in summary_lower:\n",
        "            critical_events.append(keyword)\n",
        "\n",
        "    return critical_events\n",
        "\n",
        "# Function for decision support\n",
        "def decision_support_system(sentiment, liquidity_impact, critical_events):\n",
        "    decisions = []\n",
        "\n",
        "    # Decision based on sentiment\n",
        "    if sentiment['label'] == 'NEGATIVE' and sentiment['score'] > 0.7:\n",
        "        decisions.append(\"Consider reducing exposure or monitoring closely due to negative sentiment.\")\n",
        "    elif sentiment['label'] == 'POSITIVE' and sentiment['score'] > 0.7:\n",
        "        decisions.append(\"Positive outlook; potential opportunity to increase exposure.\")\n",
        "\n",
        "    # Decision based on liquidity impact\n",
        "    if liquidity_impact == \"Negative Impact on Liquidity\":\n",
        "        decisions.append(\"Potential liquidity issues detected; reassess financial stability.\")\n",
        "    elif liquidity_impact == \"Positive Impact on Liquidity\":\n",
        "        decisions.append(\"Improved liquidity expected; may strengthen financial position.\")\n",
        "\n",
        "    # Decision based on critical events\n",
        "    if critical_events:\n",
        "        decisions.append(f\"Critical events detected: {', '.join(critical_events)}. Immediate action may be required.\")\n",
        "\n",
        "    if not decisions:\n",
        "        decisions.append(\"No immediate action required; maintain current position.\")\n",
        "\n",
        "    return decisions\n",
        "\n",
        "user_input = input(\"Enter your search query: \")\n",
        "\n",
        "# Define search strategies\n",
        "search_strategies = {\n",
        "    'raw_material_costs': f'{user_input} AND (\"raw material\" OR \"supply chain\" OR \"input cost\" OR \"steel prices\")',\n",
        "    'laws_and_regulations': f'{user_input} AND (\"emission laws\" OR \"regulations\" OR \"tax\" OR \"climate regulation\")',\n",
        "    'economic_factors': f'{user_input} AND (\"financial report\" OR \"earnings\" OR \"profit\" OR \"loss\")',\n",
        "    'industry_events': f'{user_input} AND (\"auto industry\" OR \"market downturn\" OR \"recession\")',\n",
        "    'climate_and_sustainability': f'{user_input} AND (\"climate change\" OR \"carbon footprint\" OR \"sustainability initiatives\" OR \"EV investments\")'\n",
        "}\n"
      ],
      "metadata": {
        "id": "cAP_95mDYWYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the time range (from 1 month ago to now)\n",
        "current_time = datetime.utcnow()\n",
        "two_weeks_ago = current_time - timedelta(weeks=2)\n",
        "time_str = two_weeks_ago.strftime('%Y-%m-%dT%H:%M:%S')\n",
        "\n",
        "# Function to fetch news articles using an open RSS feed\n",
        "def fetch_news(query):\n",
        "    rss_url = f\"https://news.google.com/rss/search?q={query}&hl=en-US&gl=US&ceid=US:en\"\n",
        "    response = requests.get(rss_url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.content, features=\"xml\")\n",
        "        articles = soup.findAll('item')\n",
        "        return articles\n",
        "    else:\n",
        "        print(f\"Failed to fetch news for query: {query}\")\n",
        "        return []\n",
        "\n",
        "# Main execution loop\n",
        "for strategy_name, query in search_strategies.items():\n",
        "    articles = fetch_news(query)\n",
        "\n",
        "    for article in articles:\n",
        "        # Extract relevant information from the RSS feed\n",
        "        title = article.title.text\n",
        "        link = article.link.text\n",
        "        pub_date = article.pubDate.text\n",
        "\n",
        "        # Get the text from the article's URL\n",
        "        article_text = get_text_from_url(link)\n",
        "\n",
        "        # Clean the text and get sentiment\n",
        "        cleaned_article, sentiment = clean_text(article_text)\n",
        "\n",
        "        if cleaned_article:\n",
        "            # Forecast liquidity impact\n",
        "            liquidity_impact = forecast_liquidity(title, sentiment)\n",
        "\n",
        "            # Check for critical events\n",
        "            critical_events = check_critical_events(title)\n",
        "\n",
        "            # Get decision support recommendations\n",
        "            decisions = decision_support_system(sentiment, liquidity_impact, critical_events)\n",
        "\n",
        "            # Prepare the document to insert into MongoDB (optional)\n",
        "            document = {\n",
        "                'title': title,\n",
        "                'publishedAt': pub_date,\n",
        "                'source': article.source.text if article.source else 'Unknown',\n",
        "                'cleaned_article': title,\n",
        "                'sentiment': sentiment,\n",
        "                'liquidity_impact': liquidity_impact,\n",
        "                'critical_events': critical_events,\n",
        "                'decisions': decisions\n",
        "            }\n",
        "\n",
        "            # Collect data for aggregation\n",
        "            all_sentiments.append(sentiment)\n",
        "            all_liquidity_impacts.append(liquidity_impact)\n",
        "            all_critical_events.extend(critical_events)\n",
        "            all_decisions.extend(decisions)\n",
        "            total_articles_analyzed += 1\n",
        "\n",
        "            # Optionally, insert the document into MongoDB\n",
        "            db_res = db[strategy_name].insert_one(document)\n",
        "\n",
        "            if db_res.acknowledged:\n",
        "                print(f\"Inserted article '{title}' into '{strategy_name}' collection.\")\n",
        "            else:\n",
        "                print(f\"Failed to insert article '{title}' into MongoDB.\")\n",
        "        else:\n",
        "            print(f\"Failed to clean article '{title}' for '{strategy_name}'.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Btz94S9BYYw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After processing all articles, provide overall summary\n",
        "print(\"\\n=== Overall Analysis ===\")\n",
        "\n",
        "# Sentiment Analysis\n",
        "positive_sentiments = [s for s in all_sentiments if s['label'] == 'POSITIVE']\n",
        "negative_sentiments = [s for s in all_sentiments if s['label'] == 'NEGATIVE']\n",
        "num_positive = len(positive_sentiments)\n",
        "num_negative = len(negative_sentiments)\n",
        "total_sentiments = num_positive + num_negative\n",
        "\n",
        "print(f\"Total articles analyzed: {total_articles_analyzed}\")\n",
        "print(f\"Positive sentiments: {num_positive}\")\n",
        "print(f\"Negative sentiments: {num_negative}\")\n",
        "\n",
        "# Liquidity Impact\n",
        "positive_liquidity = all_liquidity_impacts.count(\"Positive Impact on Liquidity\")\n",
        "negative_liquidity = all_liquidity_impacts.count(\"Negative Impact on Liquidity\")\n",
        "neutral_liquidity = all_liquidity_impacts.count(\"Neutral\")\n",
        "\n",
        "print(f\"\\n=== Liquidity Impact Summary ===\")\n",
        "print(f\"Positive Impact on Liquidity: {positive_liquidity}\")\n",
        "print(f\"Negative Impact on Liquidity: {negative_liquidity}\")\n",
        "print(f\"Neutral Liquidity Impact: {neutral_liquidity}\")\n",
        "\n",
        "# Critical Events\n",
        "unique_critical_events = set(all_critical_events)\n",
        "print(f\"\\n=== Critical Events Detected ===\")\n",
        "if unique_critical_events:\n",
        "    for event in unique_critical_events:\n",
        "        print(f\"- {event}\")\n",
        "else:\n",
        "    print(\"No critical events detected.\")\n",
        "\n",
        "# Decisions\n",
        "from collections import Counter\n",
        "decision_counts = Counter(all_decisions)\n",
        "print(\"\\n=== Decision Recommendations ===\")\n",
        "for decision, count in decision_counts.items():\n",
        "    print(f\"- {decision}: {count} occurrences\")\n",
        "\n",
        "# Prepare the overall analysis document\n",
        "overall_analysis = {\n",
        "    'query': user_input,\n",
        "    'timestamp': datetime.utcnow(),\n",
        "    'total_articles_analyzed': total_articles_analyzed,\n",
        "    'sentiment_summary': {\n",
        "        'positive': num_positive,\n",
        "        'negative': num_negative,\n",
        "        'total': total_sentiments\n",
        "    },\n",
        "    'liquidity_impact_summary': {\n",
        "        'positive': positive_liquidity,\n",
        "        'negative': negative_liquidity,\n",
        "        'neutral': neutral_liquidity\n",
        "    },\n",
        "    'critical_events_detected': list(unique_critical_events),\n",
        "    'decision_recommendations': dict(decision_counts)\n",
        "}\n",
        "\n",
        "# Insert the overall analysis into MongoDB\n",
        "db_res = db['overall_analysis'].insert_one(overall_analysis)\n",
        "\n",
        "if db_res.acknowledged:\n",
        "    print(\"Overall analysis successfully inserted into MongoDB.\")\n",
        "else:\n",
        "    print(\"Failed to insert overall analysis into MongoDB.\")"
      ],
      "metadata": {
        "id": "5b28mo2E2fge"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
